{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d8c134ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import catboost as ctb\n",
    "\n",
    "from torch import nn\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import get_scheduler\n",
    "from collections import defaultdict, OrderedDict\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score, precision_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5b69bb34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1684375, 0.8315625, 4.936920222634509, 2.221918140399081)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_train = pd.read_csv(\"dataset.csv\")\n",
    "d_test = pd.read_csv(\"test.csv\")\n",
    "count = d_train[d_train.target == 1].target.sum()\n",
    "w1, w2 = count / len(d_train), (len(d_train) - count) / len(d_train)\n",
    "k = np.sqrt(w2 / w1)\n",
    "w1, w2, w2 / w1, np.sqrt(w2 / w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "46cffb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(d_train, p):\n",
    "    id_test = []\n",
    "    id_train = []\n",
    "    for i in range(2):\n",
    "        ids = np.arange(len(d_train[d_train.target == i]))\n",
    "        if i == 0:\n",
    "            ids = np.random.choice(np.arange(len(d_train[d_train.target == i])), size=int(len(ids) / k))\n",
    "        else:\n",
    "            ids = ids.tolist() + np.random.choice(ids, size=int(len(ids) * k) - len(ids)).tolist()\n",
    "            ids = np.array(ids)\n",
    "        if i == 0:\n",
    "            mask = np.random.choice([0, 1], size=len(ids) , p=[p, 1 - p])\n",
    "        else:\n",
    "            mask = np.random.choice([0, 1], size=len(ids), p=[p, 1 - p])\n",
    "        id_test.extend(list(set(np.arange(len(d_train[d_train.target == i]))) - set(ids[mask == 0])))\n",
    "        id_train.extend(ids[mask == 0])\n",
    "    \n",
    "    return id_train, id_test\n",
    "\n",
    "id_train_network, id_test_network = split_dataset(d_train, 0.7)\n",
    "id_train_catboost, id_test_catboost = split_dataset(d_train, 0.7)\n",
    "id_train_forest, id_test_forest = split_dataset(d_train, 0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dfdcdac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class networkDataset(Dataset):\n",
    "    def __init__(self, dt, max_len=161):\n",
    "        super(networkDataset).__init__()\n",
    "        self.max_len = max_len\n",
    "        self.targets = dt.target.to_numpy()\n",
    "        self.dt = dt\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        value = torch.Tensor(self.dt.to_numpy()[index][:805]).float().view(self.max_len, 805 // self.max_len)\n",
    "        return torch.Tensor(value), self.targets[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "    \n",
    "def collate_fn(batch):\n",
    "    x_batch = torch.stack([elem[0] for elem in batch])\n",
    "    target_batch = torch.Tensor([elem[1] for elem in batch]).long()\n",
    "    return x_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "30993f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 805\n",
    "batch_size = 256\n",
    "ds_train = networkDataset(d_train.iloc[id_train_network], max_len)\n",
    "ds_val = networkDataset(d_train.iloc[id_test_network],  max_len)\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    dataset=ds_train,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "dataloader_val = DataLoader(\n",
    "    dataset=ds_val,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3739a202",
   "metadata": {},
   "outputs": [],
   "source": [
    "class block(nn.Module):\n",
    "    def __init__(self, input_size, output_size, dropout_p=0):\n",
    "        super(block, self).__init__()\n",
    "        self.block = nn.Sequential(OrderedDict([\n",
    "            ('lin', nn.Linear(input_size, output_size)),\n",
    "            ('act', nn.ReLU()),\n",
    "            ('drop', nn.Dropout(dropout_p)),\n",
    "            ('lnorm', nn.LayerNorm([output_size]))\n",
    "        ]))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "    \n",
    "class network(nn.Module):\n",
    "    def __init__(self, labels_count):\n",
    "        super(network, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(OrderedDict([\n",
    "            ('block1', block(805, 805)),\n",
    "            ('block2', block(805, 256)),\n",
    "            ('block3', block(256, 256)),\n",
    "            ('block4', block(256, 64)),\n",
    "            ('last_lin', nn.Linear(64, labels_count)),\n",
    "            ('logsoftmax', nn.LogSoftmax(dim=1))\n",
    "        ]))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = x.view(batch_size, -1)\n",
    "        output = self.model(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "350d90c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "def create_model_and_optimizer(model_class, model_params, lr=1e-3, beta1=0.9, beta2=0.999, device=device):\n",
    "    model = model_class(**model_params)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    optimized_params = []\n",
    "    for param in model.parameters():\n",
    "        if param.requires_grad:\n",
    "            optimized_params.append(param)\n",
    "    optimizer = torch.optim.Adam(optimized_params, lr, [beta1, beta2])\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1eac5d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, opt, loader, criterion):\n",
    "    model.train()\n",
    "    losses_tr = []\n",
    "    for x_batch, target_batch in loader:\n",
    "        opt.zero_grad()\n",
    "        x_batch = x_batch.cuda()\n",
    "        target_batch = target_batch.cuda()\n",
    "        pred = model(x_batch)\n",
    "        loss = criterion(pred, target_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        losses_tr.append(loss.item())\n",
    "    \n",
    "    return model, opt, np.mean(losses_tr)\n",
    "\n",
    "\n",
    "def val(model, loader, criterion, metric_names=None):\n",
    "    model.eval()\n",
    "    losses_val = []\n",
    "    if metric_names is not None:\n",
    "        metrics = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for x_batch, target_batch in loader:\n",
    "            x_batch = x_batch.cuda()\n",
    "            target_batch = target_batch.cuda()\n",
    "            pred = model(x_batch)\n",
    "            loss = criterion(pred, target_batch)\n",
    "\n",
    "            losses_val.append(loss.item())\n",
    "            \n",
    "            if metric_names is not None:\n",
    "                if 'roc-auc' in metric_names:\n",
    "                    pred_labels = torch.argmax(pred.cpu(), dim=1)\n",
    "                    metrics['roc-auc'].append(roc_auc_score(target_batch.cpu().numpy(), pred_labels.numpy()))\n",
    "                if 'precision' in metric_names:\n",
    "                    pred_labels = torch.argmax(pred.cpu(), dim=1)\n",
    "                    metrics['precision'].append(precision_score(target_batch.cpu().numpy(), pred_labels.numpy()))\n",
    "                if 'accuracy' in metric_names:\n",
    "                    preds = torch.argsort(pred, dim=1, descending=True)\n",
    "                    for k in metric_names[\"accuracy\"][\"top\"]:\n",
    "                        metrics[f'accuracy ~ top#{k}'].append(\n",
    "                            np.mean([libs_batch[i].item() in preds[i, :k] for i in range(target_batch.shape[0])])\n",
    "                        )\n",
    "\n",
    "        if metric_names is not None:\n",
    "            for name in metrics:\n",
    "                metrics[name] = np.mean(metrics[name])\n",
    "    \n",
    "    return np.mean(losses_val), metrics if metric_names else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bd81ca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "\n",
    "def learning_loop(\n",
    "    model,\n",
    "    optimizer,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    scheduler=None,\n",
    "    min_lr=None,\n",
    "    epochs=10,\n",
    "    val_every=1,\n",
    "    metric_names=None\n",
    "):  \n",
    "    for epoch in range(1, epochs+1):\n",
    "        model, optimizer, loss = train(model, optimizer, train_loader, criterion)\n",
    "\n",
    "        if not (epoch % val_every):\n",
    "            loss, metrics_ = val(model, val_loader, criterion, metric_names=metric_names)\n",
    "            if scheduler:\n",
    "                try:\n",
    "                    scheduler.step()\n",
    "                except:\n",
    "                    scheduler.step(loss)\n",
    "        \n",
    "        if min_lr and get_lr(optimizer) <= min_lr:\n",
    "            break\n",
    "    \n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "69880048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model():\n",
    "    w1 = [1, 0.9, 0.8, 0.7]\n",
    "    w2 = [1, 0.1, 0.2, 0.3]\n",
    "    results = []\n",
    "    w = []\n",
    "    val_data = torch.Tensor(d_train.iloc[id_test_network].drop([\"target\"], axis=1).to_numpy()).float()\n",
    "    val_data = val_data.to(device)\n",
    "    val_targets = d_train.iloc[id_test_network]['target']\n",
    "    for i in tqdm(range(len(w1))):\n",
    "        for j in tqdm(range(len(w2))):\n",
    "            model, optimizer = create_model_and_optimizer(\n",
    "                model_class = network,\n",
    "                model_params = {\n",
    "                    \"labels_count\": 2\n",
    "                },\n",
    "                lr = 1e-3,\n",
    "                device = device\n",
    "            )\n",
    "            criterion = nn.NLLLoss(weight=torch.Tensor([w2[j], w1[i]]).float().to(device))\n",
    "            scheduler = get_scheduler(\"cosine_with_restarts\", optimizer, 10, 50)\n",
    "            model, optimizer = learning_loop(\n",
    "                model = model,\n",
    "                optimizer = optimizer,\n",
    "                train_loader = dataloader_train,\n",
    "                val_loader = dataloader_val,\n",
    "                criterion = criterion,\n",
    "                scheduler = scheduler,\n",
    "                epochs = 50,\n",
    "                min_lr = 1e-6,\n",
    "                val_every = 1\n",
    "            )\n",
    "            pred = model(val_data)\n",
    "            pred = torch.argmax(pred.cpu(), dim=1)\n",
    "            results.append(roc_auc_score(val_targets, pred.numpy()))\n",
    "            w.append([w2[j], w1[i]])\n",
    "    results = torch.Tensor(results)\n",
    "    best = torch.argmax(results).tolist()\n",
    "    return w[best]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2027e00e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb49a2278df14047a40430a7130e1e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c5e958477df4329a8ff10ece5610591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9593b7c38b6e41dda66f0e429e65d363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ad97d019e64d2c9cfdbf046cc0d565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fa117d04ff74d7b99b7b78613547246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_network = get_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c3ff8b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1, 1]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e86ba440",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer = create_model_and_optimizer(\n",
    "    model_class = network,\n",
    "    model_params = {\n",
    "        \"labels_count\": 2\n",
    "    },\n",
    "    lr = 1e-3,\n",
    "    device = device\n",
    ")\n",
    "criterion = nn.NLLLoss(weight=torch.Tensor([0.1, 1]).float().to(device))\n",
    "scheduler = get_scheduler(\"cosine_with_restarts\", optimizer, 10, 50)\n",
    "model, optimizer = learning_loop(\n",
    "    model = model,\n",
    "    optimizer = optimizer,\n",
    "    train_loader = dataloader_train,\n",
    "    val_loader = dataloader_val,\n",
    "    criterion = criterion,\n",
    "    scheduler = scheduler,\n",
    "    epochs = 50,\n",
    "    min_lr = 1e-6,\n",
    "    val_every = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "197a9ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_network = model(torch.Tensor(values.to_numpy()).float().to(device))\n",
    "predict_network = torch.argmax(predict_network.cpu(), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d26f00a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(predict_network, columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6c3ac55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"submission.csv\", sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
